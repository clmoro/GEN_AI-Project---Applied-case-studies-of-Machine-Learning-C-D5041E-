{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4114ab-42f6-4e5d-a4a9-71b1970ce14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ccd56",
   "metadata": {},
   "source": [
    "#### HuggingFace token\n",
    "This token is mandatory. Register on the website and generate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0e99ed-024f-47e2-a98e-16a3697040fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "access_token = \"secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03ac3c3-8626-4b93-9beb-2ffd8be2ed65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506b23f-b0ef-4f4a-a79d-d19afa0fa8ff",
   "metadata": {},
   "source": [
    "### 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel, TFBertForQuestionAnswering,TFAutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501bb050-01d4-4558-9955-3ca9e02502ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "GPU_use = 2\n",
    "st = \"cuda:\"+str(GPU_use)\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(GPU_use) \n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "#st = \"cpu\"\n",
    "#torch.device(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d12b7e-c5fd-413d-b19e-6d04bbafb84b",
   "metadata": {},
   "source": [
    "### 2. Choose the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979400de-5fce-45cc-b434-4cadf7e155fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = 'meta-llama/Meta-Llama-3-8B'\n",
    "#base_model = 'meta-llama/Llama-3.2-1B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c838824-c121-4d29-ad85-e2d445c821af",
   "metadata": {},
   "source": [
    "### 3.Importing the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fda458-1360-476c-aff4-d6f3343ae071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokr = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16c3230-d8c7-4f2e-b48e-ffc4c2116e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = tokr(\"ciao come stai?\",return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2051c998-6eba-4b20-a6d4-1a0421229a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,     66,  23332,   2586,    357,   2192,     30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80feb7a6-d50c-41ae-a3b0-c819f041965f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>ciao come stai?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokr.batch_decode(toks['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3b518-f116-4a75-84d7-92760599ca5e",
   "metadata": {},
   "source": [
    "### 4. importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb44a4b9-4ca7-4db7-8b59-daa098f7353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(base_model, torch_dtype=torch.bfloat16, device_map=GPU_use,\n",
    "                                             token=access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c0c46-1729-4440-9bcf-ac6563f00aea",
   "metadata": {},
   "source": [
    "### 5. setting the correct prompt (different for each models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e65b8027-83de-4f9e-8fb0-500bc24476e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "USER: {}\n",
    "===\n",
    "{}\n",
    "ASSISTANT:\"\"\"\n",
    "\n",
    "def sql_prompt(d): return fmt.format(d[\"context\"], d[\"question\"])\n",
    "def question(table, quest):\n",
    "    tst = {'context' : '', 'question':''}\n",
    "    tst['context'] = table\n",
    "    tst['question'] = quest\n",
    "    return sql_prompt(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddba88f-3362-4fd0-9a8b-d59fe895c15f",
   "metadata": {},
   "source": [
    "### 6. play with the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bea873d-de33-45bb-94fe-0b668bdb4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 342 ms, total: 3.14 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t = 'Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry\\'s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'\n",
    "q = 'translate from english to italian'\n",
    "\n",
    "\n",
    "#t =''\n",
    "#q = 'hi, how are you?'\n",
    "#print(question(t,q))\n",
    "test = question(t,q)\n",
    "toks = tokr(test, return_tensors=\"pt\")\n",
    "res = model.generate(**toks.to(st), max_new_tokens=100, top_p = 0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eadd62a2-e0c0-40fe-b8d3-06134926f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "USER: Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
      "===\n",
      "translate from english to italian\n",
      "ASSISTANT: Lorem Ipsum è semplicemente un testo di esempio utilizzato nel settore della stampa e della composizione tipografica. Lorem Ipsum è stato il testo di esempio standard della stampa sin dal 1500, quando un tipografo sconosciuto prese una gallea di caratteri e la mescolò per creare un libro di esempi di caratteri. È sopravvissuto non solo ai cinque secoli\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "print(tokr.batch_decode(res)[0].replace(\"*\",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768f5e5-c196-4e1d-88ff-709811df0210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
