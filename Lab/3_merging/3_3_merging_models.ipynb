{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1eaa37-cbbf-4299-b159-f32872350ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Important imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ccd56",
   "metadata": {},
   "source": [
    "#### token hugging face\n",
    "This token is mandatory. Register on the website and generate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0e99ed-024f-47e2-a98e-16a3697040fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "access_token = \"secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03ac3c3-8626-4b93-9beb-2ffd8be2ed65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac2d7c-6434-43de-bd3d-e451bcb30cfa",
   "metadata": {},
   "source": [
    "### 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501bb050-01d4-4558-9955-3ca9e02502ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "GPU_use = 2\n",
    "st = \"cuda:\"+str(GPU_use)\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(GPU_use) \n",
    "print(torch.cuda.current_device())\n",
    "#st = \"cpu\"\n",
    "#torch.device(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a836d30-0ef1-4137-8a0c-b8412a098002",
   "metadata": {},
   "source": [
    "### 2. Quick look to the dataset updated before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347da631-6aa0-4986-a2cc-bbd3875ec13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2003094f-fd31-449f-9777-1ba617eb0506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset('username/dataset_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e3a213-3e15-4756-99b8-07dc18d7232b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answer'],\n",
       "        num_rows: 58800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117a6f72-e147-46b3-8593-8c0f6d274b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"context\": \"table([ eof x: -69 y: -148 z: 662, gripper: open , Black-Cup x: -276 y: -137 z: 80, Plate x: -47 y: 251 z: 30, Bowl x: -219 y: 41 z: 100, White-Cup x: -195 y: 311 z: 80, Apple x: 131 y: 14 z: 50 or: 124, Banana x: -51 y: 118 z: 30 or: 99, Carrot x: 238 y: 13 z: 30 or: 116, Chili x: 322 y: 179 z: 40 or: 143, Coke-Can x: -12 y: 85 z: 70 or: 6, Corn x: -376 y: -282 z: 30 or: 9, Eggplant x: -300 y: 16 z: 50 or: 165, Gear x: -347 y: -425 z: 20 or: 70, Grape x: 60 y: -106 z: 20 or: 81, Green-Block x: 119 y: -328 z: 80 or: 76, Green-Cylinder x: 115 y: -126 z: 40 or: 151, Green-Parallelepiped x: -20 y: -382 z: 80 or: 18, Green-Pepper x: 418 y: 207 z: 80 or: 100, Grey-Block x: -161 y: 248 z: 80 or: 86, Orange x: -149 y: 394 z: 50 or: 104, Pineapple x: -158 y: -276 z: 50 or: 170, Red-Block x: 201 y: 176 z: 40 or: 138, Red-Triangle x: 421 y: -18 z: 40 or: 106, Rivella Bottle x: -222 y: -439 z: 100 or: 169, Tomato x: 361 y: 199 z: 50 or: 147, Yellow Ball x: 251 y: 35 z: 50 or: 57 ])\",\n",
      "  \"question\": \"pick Orange and place to Black-Cup\",\n",
      "  \"answer\": \"-149+0;394+0;50+300;104,-149+0;394+0;50+0;104,close,-149+0;394+0;50+300;104,-276+0;-137+0;80+300;0,-276+0;-137+0;80+50;0,open,home\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trn = ds['train']\n",
    "import json\n",
    "print(json.dumps(trn[14], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d12b7e-c5fd-413d-b19e-6d04bbafb84b",
   "metadata": {},
   "source": [
    "### 3.Merging the fine-tuned model with the GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9c0b6c-02c6-4d06-83d7-40b3b8c37053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel, TFBertForQuestionAnswering,TFAutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979400de-5fce-45cc-b434-4cadf7e155fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards:  50%|████████████            | 2/4 [03:57<03:57, 118.54s/it]"
     ]
    }
   ],
   "source": [
    "base_model = 'meta-llama/Meta-Llama-3-8B'\n",
    "tokr = AutoTokenizer.from_pretrained(base_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, torch_dtype=torch.bfloat16, device_map=GPU_use,token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fda458-1360-476c-aff4-d6f3343ae071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qlora_model = './../qlora-out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f275f-5ee3-4ec7-a17d-39273b3ace18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, qlora_model,device_map=GPU_use,token=access_token)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6982b9-0acd-4d3a-a9c8-fb4f2d5a9a17",
   "metadata": {},
   "source": [
    "### 4. Saving the model and push to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873ad2c-4b18-4bad-9f1d-6193aaddbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('PEFT-trained-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b5366-e2de-45ca-befb-b0fff3765963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# push to the hub\n",
    "model.push_to_hub(\"marcomaccarini/TEST_LAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c0c46-1729-4440-9bcf-ac6563f00aea",
   "metadata": {},
   "source": [
    "### 5. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b8027-83de-4f9e-8fb0-500bc24476e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "USER: {}\n",
    "===\n",
    "{}\n",
    "ASSISTANT:\"\"\"\n",
    "\n",
    "def sql_prompt(d): return fmt.format(d[\"context\"], d[\"question\"])\n",
    "def question(table, quest):\n",
    "    tst = dict(**trn[8])\n",
    "    tst['context'] = table\n",
    "    tst['question'] = quest\n",
    "    return sql_prompt(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea873d-de33-45bb-94fe-0b668bdb4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t = 'table([ eof x: -69 y: -148 z: 662, gripper: open , apple x: 100, y: 30, z: 250; banana x: 300, y: 220, z: 120; pear x: 20, y: 200, z: 60; melon x: 230, y: 100, z: 50; cup x: 230, y: 320, z: 30;])'\n",
    "q = 'pick apple and place to Cup'\n",
    "\n",
    "test = question(t,q)\n",
    "toks = tokr(test, return_tensors=\"pt\")\n",
    "res = model.generate(**toks.to(st), max_new_tokens=100, top_p = 0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd62a2-e0c0-40fe-b8d3-06134926f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "print(tokr.batch_decode(res)[0].replace(\"*\",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c3c0b-511f-4f7d-9c4f-a5062f8f5bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f383a-e675-4187-865a-0723f7c86d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
